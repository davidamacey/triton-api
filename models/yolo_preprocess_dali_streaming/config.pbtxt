# YOLO Preprocessing - DALI Backend (STREAMING VARIANT)
# GPU-accelerated preprocessing pipeline for YOLO11
# Pipeline: nvJPEG decode → Warp Affine (letterbox) → Normalize → CHW transpose
#
# Optimized for: Real-time video streaming (low latency)
# - Max batch: 8 (smaller batches for lower latency)
# - Batching delay: 1ms (ultra-low latency)
#
# Uses fn.warp_affine for exact Ultralytics LetterBox compatibility:
# - Scale + translate + pad in single GPU operation
# - Centered padding with gray (114, 114, 114)
# - Requires affine transformation matrix per image
#
# NVIDIA Best Practices:
# - device="mixed" for image decoder (uses nvJPEG GPU acceleration)
# - instance count=1 (NVIDIA warning: count>1 causes unnaturally high memory usage)
# - hw_decoder_load=0.65 (optimal for Ampere+ hardware decoder offload)

name: "yolo_preprocess_dali_streaming"
backend: "dali"
max_batch_size: 8

input [
  {
    name: "encoded_images"
    data_type: TYPE_UINT8
    dims: [ -1 ]  # Variable-length JPEG bytes
  },
  {
    name: "affine_matrices"
    data_type: TYPE_FP32
    dims: [ 2, 3 ]  # 2x3 affine transformation matrix per image
  }
]

output [
  {
    name: "preprocessed_images"
    data_type: TYPE_FP32
    dims: [ 3, 640, 640 ]  # CHW format, normalized [0, 1]
  }
]

# NVIDIA Best Practice: Use count=1 to avoid unnaturally increased memory consumption
# See: https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/dali_backend/
# DUAL-GPU CONFIGURATION: Streaming variant across both A6000 GPUs
instance_group [
  {
    count: 6         # GPU 0: 6 instances for streaming workload
    kind: KIND_GPU
    gpus: [ 0 ]
  },
  {
    count: 6         # GPU 1 (host GPU 2): 6 instances for streaming workload
    kind: KIND_GPU
    gpus: [ 1 ]
  }
]

# Dynamic batching for DALI preprocessing (streaming: ultra-low latency)
dynamic_batching {
  preferred_batch_size: [ 2, 4, 8 ]
  max_queue_delay_microseconds: 1000  # 1ms - ultra-low latency for real-time streaming
  preserve_ordering: true  # Maintain frame order for video streams
}

parameters: {
  key: "num_threads"
  value: { string_value: "4" }
}
